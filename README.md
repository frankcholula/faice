# fAIce ğŸ«¥
EEEM068 Spring 2025 Applied Machine Learning Project: Human Faces Generation with Diffusion Models

## Code Layout
```bash
faice/code
â”œâ”€â”€ code
â”‚Â Â  â”œâ”€â”€ args.py
â”‚Â Â  â”œâ”€â”€ conf
â”‚Â Â  â”œâ”€â”€ datasets
â”‚Â Â  â”œâ”€â”€ eda
â”‚Â Â  â”œâ”€â”€ experiments
â”‚Â Â  â”œâ”€â”€ main.py
â”‚Â Â  â”œâ”€â”€ Makefile
â”‚Â Â  â”œâ”€â”€ models
â”‚Â Â  â”œâ”€â”€ pipelines
â”‚Â Â  â”œâ”€â”€ runs
â”‚Â Â  â””â”€â”€ utils
â”œâ”€â”€ docs
â”œâ”€â”€ environment.yml
â”œâ”€â”€ LICENSE
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â””â”€â”€ Surrey_CSEE_Thesis_Template
```

## Running the Experiments
Pleas see the `experiments` folder for running the experments.
You have the option to use the `Makefile` as well. 
```bash
python main.py \
    --dataset face \
    --scheduler ddpm \
    --beta_schedule linear \
    --model unet \
    --unet_variant ddpm \
    --image_size 128 \
    --num_epochs 500 \
    --train_batch_size 64 \
    --eval_batch_size 64 \
    --wandb_run_name baseline \
    --calculate_fid \
    --calculate_is \
    --verbose
```
Please use the `--verbose` flag to check your parameters before running the experiments.

âš ï¸ **Unless you're running hyperparameter tuning, please make sure yoru experiement batch size is consistent for the ablation study**
1. If you're running the experiments on `Otter`, please lock the batch size to `24` for memory reasons. 
2. If you're running the experiments on `Eureka2`, please set the batch size to `64` for faster training.

## Dataset
As seen in the code layout above, please download the attached dataset `celeba_hq_split.zip` from the email and extract it into the `datasets` folder in order to run the code.

## Credentials
Please use the provided API key and entity in the `.env` file in order to store the runs on Weights & Biases.
```bash
# sample .env file WANDB_ENTITY=<your_wandb_entity>
WANDB_API_KEY=<your_wandb_api_key>
```
ğŸš¨ **DO NOT COMMIT THE CREDENTIALS**
